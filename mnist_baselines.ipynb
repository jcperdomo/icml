{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from setup_mnist import *\n",
    "from keras.models import Input, Model\n",
    "from keras.layers import Average\n",
    "import tensorflow as tf\n",
    "from noise_functions_dl import GradientDescentDL, gradientDescentFunc\n",
    "from functools import partial\n",
    "from mwu import adversary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = MNIST()\n",
    "X_exp = np.load(\"multiclass_data_2/X_exp.npy\")\n",
    "Y_exp = np.load(\"multiclass_data_2/Y_exp.npy\")\n",
    "Target_exp = np.load(\"multiclass_data_2/Target_exp.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_exp = X_exp.reshape(-1, 28, 28, 1)\n",
    "Y_exp = np.array([(np.arange(10) == l).astype(np.float32) for l in Y_exp])\n",
    "Target_exp = np.array([(np.arange(10) == l).astype(np.float32) for l in Target_exp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ensembleModels(models, model_input):\n",
    "    # taken from https://medium.com/@twt446/ensemble-and-store-models-in-keras-2-x-b881a6d7693f\n",
    "    # collect outputs of models in a list\n",
    "    yModels=[model(model_input) for model in models] \n",
    "    # averaging outputs\n",
    "    yAvg=Average()(yModels) \n",
    "    # build model from same input and avg output\n",
    "    modelEns = Model(inputs=model_input, outputs=yAvg, name='ensemble')  \n",
    "    return modelEns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_dir = \"deep_networks\"\n",
    "models = [conv_net(False, 2, 200, model_dir + \"/conv0\"), conv_net(True, 2, 200, model_dir + \"/conv1\"), \n",
    "          conv_net(True, 4, 64, model_dir + \"/conv2\"), multilayer(4, 128, model_dir + \"/mlp0\"),\n",
    "          multilayer(2, 256, model_dir + \"/mlp1\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 2ms/step\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "100/100 [==============================] - 0s 487us/step\n",
      "100/100 [==============================] - 0s 522us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.0007815231964968916, 1.0],\n",
       " [0.0009589233167935163, 1.0],\n",
       " [9.794235913432203e-05, 1.0],\n",
       " [0.00961893867701292, 1.0],\n",
       " [0.008963608406484127, 1.0]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model.evaluate(X_exp, Y_exp) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 4ms/step\n",
      "100/100 [==============================] - 0s 2ms/step\n",
      "100/100 [==============================] - 0s 2ms/step\n",
      "100/100 [==============================] - 0s 789us/step\n",
      "100/100 [==============================] - 0s 858us/step\n",
      "[[0.0007815231964968916, 1.0], [0.0009589233167935163, 1.0], [9.794235913432203e-05, 1.0], [0.00961893867701292, 1.0], [0.008963608406484127, 1.0]]\n",
      "100/100 [==============================] - 0s 3ms/step\n",
      "[0.00391148978844285, 1.0]\n"
     ]
    }
   ],
   "source": [
    "alpha = 2.8\n",
    "lr = .001\n",
    "opt_iters=3000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    model_dir = \"deep_networks\"\n",
    "    models = [conv_net(False, 2, 200, model_dir + \"/conv0\"), conv_net(True, 2, 200, model_dir + \"/conv1\"), \n",
    "              conv_net(True, 4, 64, model_dir + \"/conv2\"), multilayer(4, 128, model_dir + \"/mlp0\"),\n",
    "              multilayer(2, 256, model_dir + \"/mlp1\")]\n",
    "    model_input = Input(shape=models[0].input_shape[1:])\n",
    "    ensemble = ensembleModels(models, model_input)\n",
    "    ensemble.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    print [model.evaluate(X_exp, Y_exp) for model in models]\n",
    "    print ensemble.evaluate(X_exp, Y_exp)\n",
    "    attack_obj = GradientDescentDL(sess, [ensemble], alpha, (28, 1, 10), (-.5, .5), \n",
    "                                   targeted=False, batch_size=1, max_iterations=opt_iters,\n",
    "                                   learning_rate=lr, confidence=0)\n",
    "    \n",
    "    noise_func = partial(gradientDescentFunc, attack=attack_obj)\n",
    "    \n",
    "    V = adversary(np.array([1.0]), [ensemble], X_exp, Y_exp, alpha, noise_func, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"ensemble_sol_mnist_dl_untargeted_2_8.npy\", V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dir = \"deep_networks\"\n",
    "models = [conv_net(False, 2, 200, model_dir + \"/conv0\"), conv_net(True, 2, 200, model_dir + \"/conv1\"), \n",
    "          conv_net(True, 4, 64, model_dir + \"/conv2\"), multilayer(4, 128, model_dir + \"/mlp0\"),\n",
    "          multilayer(2, 256, model_dir + \"/mlp1\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ensemble_noise = np.load(\"ensemble_sol_mnist_dl_untargeted_2_8.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 6ms/step\n",
      "100/100 [==============================] - 0s 4ms/step\n",
      "100/100 [==============================] - 0s 4ms/step\n",
      "100/100 [==============================] - 0s 3ms/step\n",
      "100/100 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "ensemble_res = [model.evaluate(X_exp + V, Y_exp)[1] for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(ensemble_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble Baseline is 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 2.8\n",
    "lr = .001\n",
    "opt_iters=3000\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    model_dir = \"deep_networks\"\n",
    "    models = [conv_net(False, 2, 200, model_dir + \"/conv0\"), conv_net(True, 2, 200, model_dir + \"/conv1\"), \n",
    "              conv_net(True, 4, 64, model_dir + \"/conv2\"), multilayer(4, 128, model_dir + \"/mlp0\"),\n",
    "              multilayer(2, 256, model_dir + \"/mlp1\")]\n",
    "    model_input = Input(shape=models[0].input_shape[1:])\n",
    "    individual_noise = []\n",
    "    for model in models:\n",
    "        attack_obj = GradientDescentDL(sess, [model], alpha, (28, 1, 10), (-.5, .5), \n",
    "                                       targeted=False, batch_size=1, max_iterations=opt_iters,\n",
    "                                       learning_rate=lr, confidence=0)\n",
    "        noise_func = partial(gradientDescentFunc, attack=attack_obj)\n",
    "        V = adversary(np.array([1.0]), [model], X_exp, Y_exp, alpha, noise_func, False)\n",
    "        individual_noise.append(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 1ms/step\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "100/100 [==============================] - 0s 116us/step\n",
      "100/100 [==============================] - 0s 166us/step\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "100/100 [==============================] - 0s 79us/step\n",
      "100/100 [==============================] - 0s 121us/step\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "100/100 [==============================] - 0s 72us/step\n",
      "100/100 [==============================] - 0s 109us/step\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "100/100 [==============================] - 0s 206us/step\n",
      "100/100 [==============================] - 0s 93us/step\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "100/100 [==============================] - 0s 81us/step\n",
      "100/100 [==============================] - 0s 117us/step\n"
     ]
    }
   ],
   "source": [
    "max_model = min([max([model.evaluate(X_exp + noise, Y_exp)[1] for model in models]) for noise in individual_noise])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Individual Model is .99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"mnist_dl_individual_baselines.npy\", np.array(individual_noise))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Targeted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 9ms/step\n",
      "100/100 [==============================] - 0s 4ms/step\n",
      "100/100 [==============================] - 0s 3ms/step\n",
      "100/100 [==============================] - 0s 3ms/step\n",
      "100/100 [==============================] - 0s 3ms/step\n",
      "[[15.556627197265625, 0.0], [15.009902305603028, 0.0], [15.542401428222655, 0.0], [11.18965087890625, 0.0], [13.649660949707032, 0.0]]\n",
      "100/100 [==============================] - 1s 7ms/step\n",
      "[11.793057594299317, 0.0]\n"
     ]
    }
   ],
   "source": [
    "alpha = 3.0\n",
    "lr = .001\n",
    "opt_iters=3000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    model_dir = \"deep_networks\"\n",
    "    models = [conv_net(False, 2, 200, model_dir + \"/conv0\"), conv_net(True, 2, 200, model_dir + \"/conv1\"), \n",
    "              conv_net(True, 4, 64, model_dir + \"/conv2\"), multilayer(4, 128, model_dir + \"/mlp0\"),\n",
    "              multilayer(2, 256, model_dir + \"/mlp1\")]\n",
    "    model_input = Input(shape=models[0].input_shape[1:])\n",
    "    ensemble = ensembleModels(models, model_input)\n",
    "    ensemble.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    print [model.evaluate(X_exp, Target_exp) for model in models]\n",
    "    print ensemble.evaluate(X_exp, Target_exp)\n",
    "    attack_obj = GradientDescentDL(sess, [ensemble], alpha, (28, 1, 10), (-.5, .5), \n",
    "                                   targeted=True, batch_size=1, max_iterations=opt_iters,\n",
    "                                   learning_rate=lr, confidence=0)\n",
    "    \n",
    "    noise_func = partial(gradientDescentFunc, attack=attack_obj)\n",
    "    targeted_ensemble = adversary(np.array([1.0]), [ensemble], X_exp, Y_exp, alpha, noise_func, Target_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save(\"ensemble_sol_mnist_dl_targeted_3_0.npy\", np.array(targeted_ensemble))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 1ms/step\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "100/100 [==============================] - 0s 87us/step\n",
      "100/100 [==============================] - 0s 105us/step\n"
     ]
    }
   ],
   "source": [
    "ensemble_res = [model.evaluate(X_exp + targeted_ensemble, Target_exp)[1] for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(ensemble_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Targeted Ensemble Baseline is 0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 3.0\n",
    "lr = .001\n",
    "opt_iters=3000\n",
    "with tf.Session() as sess:\n",
    "    model_dir = \"deep_networks\"\n",
    "    models = [conv_net(False, 2, 200, model_dir + \"/conv0\"), conv_net(True, 2, 200, model_dir + \"/conv1\"), \n",
    "              conv_net(True, 4, 64, model_dir + \"/conv2\"), multilayer(4, 128, model_dir + \"/mlp0\"),\n",
    "              multilayer(2, 256, model_dir + \"/mlp1\")]\n",
    "    individual_noise_targeted = []\n",
    "    for model in models:\n",
    "        attack_obj = GradientDescentDL(sess, [model], alpha, (28, 1, 10), (-.5, .5), \n",
    "                                       targeted=True, batch_size=1, max_iterations=opt_iters,\n",
    "                                       learning_rate=lr, confidence=0)\n",
    "        noise_func = partial(gradientDescentFunc, attack=attack_obj)\n",
    "        noise = adversary(np.array([1.0]), [model], X_exp, Y_exp, alpha, noise_func, Target_exp)\n",
    "        individual_noise_targeted.append(noise)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
