{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from setup_mnist import MNIST\n",
    "import helper\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from cvxopt import matrix, solvers\n",
    "from itertools import product\n",
    "import sys\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = MNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = data.train_data.reshape(-1, 28*28)\n",
    "Y_train = np.argmax(data.train_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = data.test_data.reshape(-1, 28*28)\n",
    "Y_test = np.argmax(data.test_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5444, 6179, 5470, 5638, 5307, 4987, 5417, 5715, 5389, 5454]),\n",
       " array([ 0. ,  0.9,  1.8,  2.7,  3.6,  4.5,  5.4,  6.3,  7.2,  8.1,  9. ]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_second(lst):import numpy as np\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "class LinearBinaryClassifier(object):\n",
    "    \"\"\"\n",
    "    Class for Linear Binary Classifiers\n",
    "\n",
    "    weights: np array of shape (dim, 1)\n",
    "    bias: scalar\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, weights, bias):\n",
    "        self.dim = weights.shape[0]\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        X: np array of shape (num_points, dim)\n",
    "\n",
    "        returns: a vector of shape (num_points,) with predicted labels for each point\n",
    "        \"\"\"\n",
    "        return np.sign(np.matmul(X, self.weights) + self.bias).T[0]\n",
    "\n",
    "    def distance(self, X):\n",
    "        \"\"\"\n",
    "        Computes the signed distance from a point to the decision boundary (hyperplane)\n",
    "\n",
    "        returns: a vector of shape (num_points,) with the correspoding distances\n",
    "        \"\"\"\n",
    "        return abs((np.matmul(X, self.weights) + self.bias) / np.linalg.norm(self.weights)).T[0]\n",
    "\n",
    "    def evaluate(self, X, Y):\n",
    "        \"\"\"\n",
    "        returns accuracy\n",
    "        \"\"\"\n",
    "        return np.mean(np.equal(self.predict(X), Y))\n",
    "\n",
    "    def gradient(self, X, Y):\n",
    "        \"\"\"\n",
    "        returns gradient\n",
    "        \"\"\"\n",
    "        if not hasattr(Y, \"__len__\"):  # make it robust to single items\n",
    "            X = X.reshape(1, self.dim)\n",
    "            Y = np.array([Y])\n",
    "\n",
    "        return np.array([Y[i] * self.weights.reshape(-1, ) if self.predict(X[i]) == Y[i]\n",
    "                         else np.zeros(self.dim) for i in xrange(len(X))])\n",
    "\n",
    "    def rhinge_loss(self, X, Y):\n",
    "        \"\"\"\n",
    "        returns average reverse hinge loss of classifier on X, Y\n",
    "\n",
    "        defined as max{0, y(<w,x> + b)}\n",
    "        \"\"\"\n",
    "        if not hasattr(Y, \"__len__\"):  # make it robust to single items\n",
    "            X = X.reshape(1, self.dim)\n",
    "            Y = np.array([Y])\n",
    "\n",
    "        res = np.maximum(0, Y.reshape(-1, 1) * (np.matmul(X, self.weights) + self.bias))\n",
    "        return np.mean(res.reshape(-1, ))\n",
    "\n",
    "\n",
    "def trainLBC(X, Y):\n",
    "    model = svm.SVC(kernel=\"linear\")\n",
    "    model.fit(X, Y)\n",
    "    return LinearBinaryClassifier(model.coef_.T, model.intercept_)\n",
    "\n",
    "\n",
    "class LinearOneVsAllClassifier(object):\n",
    "    \"\"\"\n",
    "    Class for Lin Binary Classifiers\n",
    "\n",
    "    weights: np array of shape (num_classes, dim)\n",
    "    bias: scalar\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes, weights, bias):\n",
    "        self.dim = weights.shape[1]\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        X: np array of shape (num_points, dim)\n",
    "\n",
    "        returns: a vector of shape (num_points,) with predicted labels for each point\n",
    "        \"\"\"\n",
    "        return np.argmax(np.matmul(X, self.weights.T) + self.bias, axis=1)\n",
    "\n",
    "    def distance(self, X):\n",
    "        \"\"\"\n",
    "        Computes the signed distance from a point to the decision boundary (hyperplane)\n",
    "\n",
    "        returns: a vector of shape (num_points,) with the correspoding distances\n",
    "        \"\"\"\n",
    "        n = X.shape[0]\n",
    "        Y = self.predict(X)\n",
    "\n",
    "        distances = []\n",
    "        for i in xrange(n):\n",
    "            label_options = range(10)\n",
    "            del label_options[Y[i]]\n",
    "            dists = []\n",
    "            for j in label_options:\n",
    "                v = tryRegionOneVsAll([self], [j], X[i])\n",
    "                dists.append(np.linalg.norm(v))\n",
    "            distances.append(min(dists))\n",
    "        return distances\n",
    "\n",
    "    def evaluate(self, X, Y):\n",
    "        \"\"\"\n",
    "        returns accuracy\n",
    "        \"\"\"\n",
    "        return np.mean(np.equal(self.predict(X), Y))\n",
    "\n",
    "    def gradient(self, X, targets):\n",
    "        \"\"\"\n",
    "        returns gradient\n",
    "        \"\"\"\n",
    "        preds = np.matmul(X, self.weights.T) + self.bias\n",
    "        n = X.shape[0]\n",
    "\n",
    "        gradient = []\n",
    "\n",
    "        for i in xrange(n):\n",
    "            target = targets[i]\n",
    "            others = range(10)\n",
    "            del others[target]\n",
    "\n",
    "            if np.argmax(preds[i]) == target:\n",
    "                res = np.zeros(self.dim)\n",
    "            else:\n",
    "                max_ix = get_max(preds[i], target)[0]\n",
    "                w_max = self.weights[max_ix]\n",
    "                w_target = self.weights[target]\n",
    "                res = w_max - w_target\n",
    "            gradient.append(res)\n",
    "        return np.array(gradient)\n",
    "\n",
    "    def rhinge_loss(self, X, targets):\n",
    "        preds = np.matmul(X, self.weights.T) + self.bias\n",
    "        res = []\n",
    "        for i in xrange(len(X)):\n",
    "            target = targets[i]\n",
    "            if np.argmax(preds) != target:\n",
    "                max_ix, max_val = get_max(preds[i], target)\n",
    "                loss = max_val - preds[i][target]\n",
    "            else:\n",
    "                loss = 0\n",
    "            res.append(loss)\n",
    "        return res\n",
    "\n",
    "def trainLMC(X, Y, method):\n",
    "    if method == \"one-vs-all\":\n",
    "        model = svm.LinearSVC(loss='hinge')\n",
    "    else: # \"all-pairs\"\n",
    "        model= svm.SVC(kernel=\"linear\")\n",
    "    model.fit(X, Y)\n",
    "    if method == \"one-vs-all\":\n",
    "        res = LinearOneVsAllClassifier(10, model.coef_, model.intercept_)\n",
    "    return res\n",
    "\n",
    "    n1 = (-sys.maxint, None)\n",
    "    n2 = (-sys.maxint, None)\n",
    "    for ix, elt in enumerate(lst):\n",
    "        if elt > n1[0]:\n",
    "            n2 = n1\n",
    "            n1 = (elt, ix)\n",
    "        elif elt > n2[0]:\n",
    "            n2 = (elt, ix) \n",
    "    return n2\n",
    "\n",
    "def get_max(lst, target):\n",
    "    n1 = (-sys.maxint, None)\n",
    "    for ix, elt in enumerate(lst):\n",
    "        if ix == target:\n",
    "            continue\n",
    "        elif elt > n1[1]:\n",
    "            n1 = (ix, elt)\n",
    "    return n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_max([1,-1,3], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LinearOneVsAllClassifier(object):\n",
    "    \"\"\"\n",
    "    Class for Lin Binary Classifiers\n",
    "    \n",
    "    weights: np array of shape (num_classes, dim)\n",
    "    bias: scalar\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, weights, bias):\n",
    "        self.dim = weights.shape[1]\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        X: np array of shape (num_points, dim) \n",
    "        \n",
    "        returns: a vector of shape (num_points,) with predicted labels for each point\n",
    "        \"\"\"\n",
    "        return np.argmax(np.matmul(X, self.weights.T) + self.bias, axis=1)\n",
    "    \n",
    "    def distance(self, X):\n",
    "        \"\"\"\n",
    "        Computes the signed distance from a point to the decision boundary (hyperplane)\n",
    "\n",
    "        returns: a vector of shape (num_points,) with the correspoding distances\n",
    "        \"\"\"\n",
    "        n = X.shape[0]\n",
    "        Y = self.predict(X)\n",
    "        \n",
    "        distances = []\n",
    "        for i in xrange(n):\n",
    "            label_options = range(10)\n",
    "            del label_options[Y[i]]\n",
    "            dists = []\n",
    "            for j in label_options:\n",
    "                v = tryRegionOneVsAll([self], [j], X[i])\n",
    "                dists.append(np.linalg.norm(v))\n",
    "            distances.append(min(dists))\n",
    "        return distances\n",
    "        \n",
    "    def evaluate(self, X, Y):\n",
    "        \"\"\"\n",
    "        returns accuracy\n",
    "        \"\"\"\n",
    "        return np.mean(np.equal(self.predict(X), Y))\n",
    "    \n",
    "    def gradient(self, X, targets):\n",
    "        \"\"\"\n",
    "        returns gradient\n",
    "        \"\"\"            \n",
    "        preds = np.matmul(X, self.weights.T) + self.bias\n",
    "        n = X.shape[0]\n",
    "        \n",
    "        gradient = []\n",
    "        \n",
    "        for i in xrange(n):\n",
    "            target = targets[i]\n",
    "            others = range(10)\n",
    "            del others[target]\n",
    "            \n",
    "            if np.argmax(preds[i]) == target:\n",
    "                res = np.zeros(self.dim)\n",
    "            else:\n",
    "                max_ix = get_max(preds[i], target)[0]\n",
    "                w_max = self.weights[max_ix]\n",
    "                w_target = self.weights[target]\n",
    "                res = w_max - w_target\n",
    "            gradient.append(res)\n",
    "        return  np.array(gradient)\n",
    "    \n",
    "    def rhinge_loss(self, X, targets):\n",
    "        preds = np.matmul(X, self.weights.T) + self.bias\n",
    "        res = []\n",
    "        for i in xrange(len(X)):\n",
    "            target = targets[i]\n",
    "            if np.argmax(preds) != target:\n",
    "                max_ix, max_val = get_max(preds[i], target) \n",
    "                loss = max_val - preds[i][target]\n",
    "            else:\n",
    "                loss = 0\n",
    "            res.append(loss)\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainLMC(X, Y, method):\n",
    "    if method == \"one-vs-all\":\n",
    "        model = svm.LinearSVC(loss='hinge')\n",
    "    else: # \"all-pairs\"\n",
    "        model= svm.SVC(kernel=\"linear\")\n",
    "    model.fit(X, Y)\n",
    "    if method == \"one-vs-all\":\n",
    "        res = LinearOneVsAllClassifier(10, model.coef_, model.intercept_)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 3000 0.8632\n",
      "1 3000 6000 0.8614\n",
      "2 6000 9000 0.8638\n",
      "3 9000 12000 0.8668\n",
      "4 12000 15000 0.8686\n"
     ]
    }
   ],
   "source": [
    "# train the classifiers\n",
    "n = 5\n",
    "train_size = 3000 #len(X_train) / n\n",
    "\n",
    "classifiers = []\n",
    "\n",
    "for i in xrange(n):\n",
    "    start = train_size * i\n",
    "    end = start + train_size\n",
    "    lmc = trainLMC(X_train[start:end], Y_train[start:end], \"one-vs-all\")\n",
    "    print i, start, end, lmc.evaluate(X_test, Y_test)\n",
    "    classifiers.append(lmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = [model.distance(X_test[:10]) for model in classifiers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.array([X_test[0]])\n",
    "y = [Y_test[0]]\n",
    "print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print classifiers[0].evaluate(x,y)\n",
    "classifiers[0].gradient(x, [4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifiers[0].weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifiers[0].bias[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tryRegionOneVsAll(models, labels, x, delta=1e-10):\n",
    "    P = matrix(np.identity(x.shape[0]))\n",
    "    q = matrix(np.zeros(x.shape[0]))\n",
    "    h = []\n",
    "    G = []\n",
    "    num_models = len(models)\n",
    "    for i in xrange(num_models):\n",
    "        others = range(10)\n",
    "        target = labels[i]\n",
    "        del others[target]\n",
    "        target_w, target_b = models[i].weights[target], models[i].bias[target]\n",
    "        for j in others:\n",
    "            other_w, other_b = models[i].weights[j], models[i].bias[j]\n",
    "            ineq_val = np.dot(target_w - other_w, x) + target_b - other_b - delta\n",
    "            h.append(ineq_val)\n",
    "            G.append(other_w - target_w)   \n",
    "    h = matrix(h)\n",
    "    G = matrix(np.array(G))\n",
    "    solvers.options['show_progress'] = False\n",
    "    sol = solvers.qp(P, q, G, h)\n",
    "    if sol['status'] == 'optimal':\n",
    "        v = np.array(sol['x']).reshape(-1,)\n",
    "        perturbed_x = np.array(x + v).reshape(1, -1)\n",
    "        is_desired_label = [models[i].predict(perturbed_x)[0] == labels[i] for i in xrange(num_models)]\n",
    "        if sum(is_desired_label) == num_models:\n",
    "            return v\n",
    "        else:\n",
    "            return tryRegionOneVsAll(models, labels, x, delta * 1.5)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "x = X_test[0]\n",
    "y = Y_test[0]\n",
    "print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.78061291656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([5]), array([4]), array([9]), array([2]), array([1])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = tryRegionOneVsAll(classifiers, [5, 4, 9, 2, 1], x)\n",
    "print np.linalg.norm(v)\n",
    "[c.predict((x + v).reshape(1, -1)) for c in classifiers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distributionalOracleOneVsAll(distribution, models, x, y, alpha):\n",
    "    \n",
    "    candidates = []\n",
    "    # we should only take into consideration models that we could feasibly trick\n",
    "\n",
    "    num_models = len(models)\n",
    "    \n",
    "    labels_values = []\n",
    "    for labels in product(range(10), repeat=num_models): # iterate over all possible regions\n",
    "        is_misclassified = (np.array(labels) != y).astype(np.float32)\n",
    "        value = np.dot(is_misclassified, distribution)\n",
    "        labels_values.append((labels, value))\n",
    "    \n",
    "    values = sorted(set([value for label, value in labels_values]), reverse=True)\n",
    "    \n",
    "    for curr_value in values:\n",
    "#         print \"Curr Value\", curr_value\n",
    "        feasible_candidates = []\n",
    "        for labels in [labels for labels, val in labels_values if val == curr_value]:\n",
    "#             print labels\n",
    "            v = tryRegionOneVsAll(models, labels, x)\n",
    "            if v is not None:\n",
    "                norm = np.linalg.norm(v)\n",
    "                if norm <= alpha:\n",
    "                    feasible_candidates.append((v, norm))\n",
    "        # amongst those with the max value, return the one with the minimum norm\n",
    "        if feasible_candidates:\n",
    "            # break out of the loop since we have already found the optimal answer\n",
    "#             print \"curr_value \", curr_value\n",
    "            return min(feasible_candidates, key=lambda x: x[1])[0]\n",
    "    return np.zeros(x.shape[0]) # we can't trick anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7320.01757622\n",
      "0.77012757483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([3]), array([3]), array([3]), array([3]), array([3])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = time.time()\n",
    "v = distributionalOracleOneVsAll([1, .2, .6, .4, .5], classifiers, x, y, 1)\n",
    "print time.time() - s\n",
    "print np.linalg.norm(v)\n",
    "[c.predict((x + v).reshape(1,-1)) for c in classifiers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_means = []\n",
    "for i in xrange(10):\n",
    "    elts = np.array([x for (x,y) in zip(X_train, Y_train) if y == i])\n",
    "    mean = np.mean(elts, axis=0)\n",
    "    class_means.append(mean)\n",
    "class_means = np.array(class_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_diffs = []\n",
    "for i in xrange(10):\n",
    "    diffs = []\n",
    "    for j in xrange(10):\n",
    "        diffs.append(np.linalg.norm(class_means[i] - class_means[j]))\n",
    "    mean_diffs.append(diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_diffs = np.array(mean_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MEAN_DICT = dict(zip(range(10), [get_max(mean_diffs[i] * -1, i)[0] for i in range(10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save(\"greedy_dict.npy\", np.array(MEAN_DICT.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coordinateAscentMulti(distribution, models, x, y, alpha, greedy=False):\n",
    "    \n",
    "    num_models = len(models)\n",
    "    \n",
    "    sol = np.zeros(x.shape)\n",
    "\n",
    "    labels = [y] * num_models # initialize to the original point, of length feasible_models\n",
    "    label_options = range(10)\n",
    "    del label_options[y]\n",
    "    \n",
    "    model_options = dict(zip(range(num_models), distribution))\n",
    "    for i in xrange(num_models):\n",
    "        if greedy:\n",
    "            coord = max(model_options, key=model_options.get)\n",
    "            labels[coord] = greedy[y]\n",
    "        else:\n",
    "            coord = np.random.choice(model_options.keys())\n",
    "            labels[coord] = np.random.choice(label_options)\n",
    "\n",
    "        del model_options[coord]    \n",
    "       \n",
    "        v = tryRegionOneVsAll(models, labels, x)\n",
    "        valid_sol = False\n",
    "        if v is not None:\n",
    "            norm = np.linalg.norm(v)\n",
    "            if norm <= alpha:\n",
    "                valid_sol = True\n",
    "                sol = v\n",
    "        if not valid_sol:\n",
    "            break \n",
    "    return sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v = coordinateAscentMulti([.2, .2, .6], classifiers, x, y, 1)\n",
    "print np.linalg.norm(v)\n",
    "[c.predict((x + v).reshape(1,-1)) for c in classifiers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gradientDescentTargeted(distribution, models, x, target, alpha, learning_rate=.001, T=3000, early_stop=5):\n",
    "    v = np.zeros(len(x))\n",
    "    best_sol = (sys.maxint, v)\n",
    "    loss_queue = []\n",
    "    for i in xrange(T):\n",
    "        gradient = sum([-1 * p * model.gradient(np.array([x + v]), [target]) for p, model in zip(distribution, models)])[0]\n",
    "       \n",
    "        v += learning_rate * gradient\n",
    "        norm  = np.linalg.norm(v)\n",
    "        if norm >= alpha:\n",
    "            v = v / norm * alpha\n",
    "            \n",
    "        loss = np.dot(distribution, [model.rhinge_loss([x + v], [target])[0] for model in models])\n",
    "        \n",
    "        loss_queue = [loss] + loss_queue\n",
    "        if i >= early_stop:\n",
    "            del loss_queue[-1]\n",
    "#             print \"Len \", len(loss_queue)\n",
    "            val = loss_queue[-1]\n",
    "            if sum([val == q_val for q_val in loss_queue]) == early_stop:\n",
    "                break\n",
    "    \n",
    "        if loss < best_sol[0]:\n",
    "            best_sol = (loss, v)\n",
    "        \n",
    "        if loss == 0:\n",
    "#             print \"FOUND IT\"\n",
    "            break\n",
    "            \n",
    "#         print i, loss, [model.predict(curr_sol) for model in models], np.linalg.norm(v)\n",
    "        \n",
    "    return best_sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradientDescentUntargeted(distribution, models, x, y, alpha):\n",
    "    targets = range(10)\n",
    "    del targets[y]\n",
    "    noise_options = []\n",
    "    for target in targets:\n",
    "#         print \"Target \", target\n",
    "        sol = gradientDescentTargeted(distribution, models, x, target, alpha)\n",
    "        noise_options.append(sol)\n",
    "        if sol[0] == 0:\n",
    "#             print \"BREAK\"\n",
    "#             print [model.predict((x + sol[1]).reshape(1,-1)) for model in models]\n",
    "            return sol[1]\n",
    "    return min(noise_options, key=lambda x:x[0])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = X_test[0]\n",
    "y = Y_test[0]\n",
    "print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "v = gradientDescentUntargeted([1, 1, 1], classifiers, x, y, 1)\n",
    "print \"time \", time.time() - s \n",
    "print \"norm \", np.linalg.norm(v)\n",
    "print [c.predict((x + v).reshape(1,-1)) for c in classifiers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from helper import generate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_exp, Y_exp = generate_data(100, X_test, Y_test, classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = np.array([model.distance(X_exp) for model in classifiers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.max(d), np.min(d), np.mean(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mwu import runMWU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "greedyCoordinateAscent = partial(coordinateAscentMulti, greedy=MEAN_DICT)\n",
    "randomCoordinateAscent = partial(coordinateAscentMulti, greedy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findNoiseBoundsMulti(models, X, Y):\n",
    "    max_bounds = []\n",
    "    num_models = len(models)\n",
    "    for i in xrange(len(X)):\n",
    "        max_v = distributionalOracleOneVsAll([1] * num_models, models, X[i], Y[i], sys.maxint)\n",
    "        max_bounds.append(np.linalg.norm(max_v))\n",
    "    min_bounds = np.array([model.distance(X) for model in models]).T\n",
    "    min_bounds = np.mean(min_bounds, axis=1)\n",
    "    return min_bounds, max_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = findNoiseBoundsMulti(classifiers, X_exp[:3], Y_exp[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir(\"trash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluateCosts(models, V, X, Y):\n",
    "    return np.array([1 - model.evaluate(X + V, Y) for model in models])\n",
    "\n",
    "\n",
    "def adversary(distribution, models, X, Y, alpha, noiseFunc):\n",
    "    return np.array([noiseFunc(distribution, models, x, y, alpha) for x, y in zip(X,Y)])\n",
    "\n",
    "\n",
    "def runMWU(models, T, X, Y, alpha, noiseFunc, exp_dir, epsilon=None):\n",
    "    num_models = len(models)\n",
    "\n",
    "    if epsilon is None:\n",
    "        delta = np.sqrt(4 * np.log(num_models) / float(T))\n",
    "        epsilon = delta / 2.0\n",
    "    else:\n",
    "        delta = 2.0 * epsilon\n",
    "\n",
    "    print(\"\\nRunning MWU for {} Iterations with Epsilon {}\\n\".format(T, epsilon))\n",
    "\n",
    "    print(\"Guaranteed to be within {} of the minimax value \\n\".format(delta))\n",
    "\n",
    "    loss_history = []\n",
    "    costs = []\n",
    "    max_acc_history = []\n",
    "    v = []\n",
    "    w = []\n",
    "    action_loss = []\n",
    "\n",
    "    w.append(np.ones(num_models) / num_models)\n",
    "\n",
    "    for t in xrange(T):\n",
    "        print(\"Iteration {}\\n\".format(t))\n",
    "\n",
    "#         if t % (T * .10) == 0 and t > 0:\n",
    "#             np.save(exp_dir + \"/\" + \"weights_{}.npy\".format(t), w)\n",
    "#             np.save(exp_dir + \"/\" + \"noise_{}.npy\".format(t), v)\n",
    "#             np.save(exp_dir + \"/\" + \"loss_history_{}.npy\".format(t), loss_history)\n",
    "#             np.save(exp_dir + \"/\" + \"max_acc_history_{}.npy\".format(t), max_acc_history)\n",
    "#             np.save(exp_dir + \"/\" + \"action_loss_{}.npy\".format(t), action_loss)\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        v_t = adversary(w[t], models, X, Y, alpha, noiseFunc)\n",
    "        v.append(v_t)\n",
    "\n",
    "        cost_t = evaluateCosts(models, v_t, X, Y)\n",
    "        costs.append(cost_t)\n",
    "\n",
    "        avg_acc = np.mean((1 - np.array(costs)), axis=0)\n",
    "        max_acc = max(avg_acc)\n",
    "        max_acc_history.append(max_acc)\n",
    "\n",
    "        loss = np.dot(w[t], cost_t)\n",
    "        individual = [w[t][j] * cost_t[j] for j in xrange(num_models)]\n",
    "\n",
    "        print(\"Weights {} Sum of Weights {}\".format(w[t], sum(w[t])))\n",
    "        print(\"Maximum (Average) Accuracy of Classifier {}\".format(max_acc))\n",
    "        print(\"Cost (Before Noise) {}\".format(np.array([1 - model.evaluate(X, Y) for model in models])))\n",
    "        print(\"Cost (After Noise), {}\".format(cost_t))\n",
    "        print(\"Loss {} Loss Per Action {}\".format(loss, individual))\n",
    "\n",
    "        loss_history.append(loss)\n",
    "        action_loss.append(individual)\n",
    "\n",
    "        new_w = np.copy(w[t])\n",
    "\n",
    "        # penalize experts\n",
    "        for i in xrange(num_models):\n",
    "            new_w[i] *= (1.0 - epsilon) ** cost_t[i]\n",
    "\n",
    "        # renormalize weights\n",
    "        w_sum = new_w.sum()\n",
    "        for i in xrange(num_models - 1):\n",
    "            new_w[i] = new_w[i] / w_sum\n",
    "        new_w[-1] = 1.0 - new_w[:-1].sum()\n",
    "\n",
    "        w.append(new_w)\n",
    "\n",
    "        print(\"time spent {}\\n\".format(time.time() - start_time))\n",
    "    print(\"finished running MWU \")\n",
    "    return w, v, loss_history, max_acc_history, action_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = runMWU(classifiers, 30, X_exp, Y_exp, .3, gradientDescentUntargeted, \"trash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = X_exp[0]\n",
    "y = Y_exp[0]\n",
    "print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v = gradientDescentMulti([.2,.2,.6], classifiers, x, 5, 1, learning_rate=.0001, T=4000)\n",
    "print np.linalg.norm(v)\n",
    "[c.predict((x + v).reshape(1,-1)) for c in classifiers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
